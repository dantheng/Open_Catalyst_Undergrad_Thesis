{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoZ9Bg5_VfLB",
    "outputId": "ceb669af-df9c-4bd4-8c38-286daf2ff308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for dantheng: "
     ]
    }
   ],
   "source": [
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
    "!sudo update-alternatives --config python3\n",
    "!python3 --version\n",
    "!sudo apt install python3-pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bMAXAKtOsm3b",
    "outputId": "0bfa5ce5-591b-455f-c0bd-449757803e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.1+cu110 in c:\\users\\patron\\anaconda3\\lib\\site-packages (1.7.1+cu110)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch==1.7.1+cu110) (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch==1.7.1+cu110) (1.21.5)\n",
      "Collecting demjson==2.2.4\n",
      "  Using cached demjson-2.2.4.tar.gz (131 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [1 lines of output]\n",
      "  error in demjson setup command: use_2to3 is invalid.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-1.7.1+cu110.html\n",
      "Collecting torch-scatter==2.0.6\n",
      "  Using cached torch_scatter-2.0.6.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-sparse==0.6.9\n",
      "  Using cached torch_sparse-0.6.9.tar.gz (36 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-cluster==1.5.9\n",
      "  Using cached torch_cluster-1.5.9.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-spline-conv==1.2.1\n",
      "  Using cached torch_spline_conv-1.2.1.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-geometric==1.6.3\n",
      "  Using cached torch_geometric-1.6.3-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-sparse==0.6.9) (1.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (4.64.1)\n",
      "Requirement already satisfied: googledrivedownloader in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (2.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (1.4.4)\n",
      "Requirement already satisfied: torch in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (1.7.1+cu110)\n",
      "Collecting rdflib\n",
      "  Using cached rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (2.11.3)\n",
      "Requirement already satisfied: numba in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (0.55.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (2.8.4)\n",
      "Requirement already satisfied: ase in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (3.22.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (3.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (1.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch-geometric==1.6.3) (1.21.5)\n",
      "Collecting python-louvain\n",
      "  Using cached python_louvain-0.16-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from ase->torch-geometric==1.6.3) (3.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric==1.6.3) (2.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\patron\\anaconda3\\lib\\site-packages (from numba->torch-geometric==1.6.3) (63.4.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from numba->torch-geometric==1.6.3) (0.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from pandas->torch-geometric==1.6.3) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from pandas->torch-geometric==1.6.3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from rdflib->torch-geometric==1.6.3) (3.0.9)\n",
      "Collecting isodate<0.7.0,>=0.6.0\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from requests->torch-geometric==1.6.3) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from requests->torch-geometric==1.6.3) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from requests->torch-geometric==1.6.3) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from requests->torch-geometric==1.6.3) (2022.9.14)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from scikit-learn->torch-geometric==1.6.3) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from scikit-learn->torch-geometric==1.6.3) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\patron\\anaconda3\\lib\\site-packages (from torch->torch-geometric==1.6.3) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\patron\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric==1.6.3) (0.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\patron\\anaconda3\\lib\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib->torch-geometric==1.6.3) (1.16.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.6.3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.6.3) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.6.3) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.6.3) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\patron\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.6.3) (21.3)\n",
      "Building wheels for collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-scatter\n",
      "  Building wheel for torch-sparse (setup.py): started\n",
      "  Building wheel for torch-sparse (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-sparse\n",
      "  Building wheel for torch-cluster (setup.py): started\n",
      "  Building wheel for torch-cluster (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-cluster\n",
      "  Building wheel for torch-spline-conv (setup.py): started\n",
      "  Building wheel for torch-spline-conv (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-spline-conv\n",
      "Failed to build torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
      "Installing collected packages: torch-spline-conv, torch-scatter, torch-cluster, python-louvain, isodate, torch-sparse, rdflib, torch-geometric\n",
      "  Running setup.py install for torch-spline-conv: started\n",
      "  Running setup.py install for torch-spline-conv: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [26 lines of output]\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\torch_scatter\n",
      "  copying torch_scatter\\placeholder.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\n",
      "  copying torch_scatter\\scatter.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\n",
      "  copying torch_scatter\\segment_coo.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\n",
      "  copying torch_scatter\\segment_csr.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\n",
      "  copying torch_scatter\\utils.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\n",
      "  copying torch_scatter\\__init__.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\n",
      "  creating build\\lib.win-amd64-cpython-39\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\logsumexp.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\softmax.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\std.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\__init__.py -> build\\lib.win-amd64-cpython-39\\torch_scatter\\composite\n",
      "  running build_ext\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:287: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "    warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n",
      "  building 'torch_scatter._scatter_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-scatter\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [42 lines of output]\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\add.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\bandwidth.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\cat.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\coalesce.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\convert.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\diag.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\eye.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\index_select.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\masked_select.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\matmul.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\metis.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\mul.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\narrow.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\padding.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\permute.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\reduce.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\rw.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\saint.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\sample.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\select.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\spmm.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\spspmm.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\storage.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\tensor.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\transpose.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\utils.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  copying torch_sparse\\__init__.py -> build\\lib.win-amd64-cpython-39\\torch_sparse\n",
      "  running build_ext\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:287: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "    warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n",
      "  building 'torch_sparse._convert_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-sparse\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [24 lines of output]\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\fps.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\graclus.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\grid.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\knn.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\nearest.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\radius.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\rw.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\sampler.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  copying torch_cluster\\__init__.py -> build\\lib.win-amd64-cpython-39\\torch_cluster\n",
      "  running build_ext\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:287: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "    warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n",
      "  building 'torch_cluster._fps_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-cluster\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [21 lines of output]\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:352: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "    warnings.warn(msg.format('we could not find ninja.'))\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\basis.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\conv.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\weighting.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\__init__.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  running build_ext\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:287: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "    warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n",
      "  building 'torch_spline_conv._basis_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-spline-conv\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for torch-spline-conv did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [23 lines of output]\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "    warnings.warn(\n",
      "  running install\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\basis.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\conv.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\weighting.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  copying torch_spline_conv\\__init__.py -> build\\lib.win-amd64-cpython-39\\torch_spline_conv\n",
      "  running build_ext\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:352: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "    warnings.warn(msg.format('we could not find ninja.'))\n",
      "  C:\\Users\\Patron\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:287: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "    warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n",
      "  building 'torch_spline_conv._basis_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "torch-spline-conv\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAstronomy in c:\\users\\patron\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: quantities in c:\\users\\patron\\anaconda3\\lib\\site-packages (from PyAstronomy) (0.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\patron\\anaconda3\\lib\\site-packages (from PyAstronomy) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\patron\\anaconda3\\lib\\site-packages (from PyAstronomy) (1.9.1)\n",
      "Requirement already satisfied: bidict in c:\\users\\patron\\anaconda3\\lib\\site-packages (from PyAstronomy) (0.22.1)\n",
      "Requirement already satisfied: six in c:\\users\\patron\\anaconda3\\lib\\site-packages (from PyAstronomy) (1.16.0)\n",
      "Requirement already satisfied: kaleido in c:\\users\\patron\\anaconda3\\lib\\site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html \n",
    "pip install demjson==2.2.4 lmdb==1.1.1 ase pymatgen==2020.12.31 pyyaml==5.4 tensorboard==2.4 wandb==0.11.2\n",
    "pip install torch-scatter==2.0.6 torch-sparse==0.6.9 torch-cluster==1.5.9 torch-spline-conv==1.2.1 torch-geometric==1.6.3 -f https://data.pyg.org/whl/torch-1.7.1+cu110.html\n",
    "git clone https://github.com/Open-Catalyst-Project/ocp.git\n",
    "pip install PyAstronomy\n",
    "pip install -U kaleido\n",
    "#!pip install ase-notebook\n",
    "\n",
    "#!pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxP0RNoXbZgG",
    "outputId": "82c77802-2598-49ae-fbe1-b0aa36090d56"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade ase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbUc9hs9HEXp",
    "outputId": "8d433aac-5da6-4f0f-bd8a-139cdea76b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already up-to-date: kaleido in /usr/local/lib/python3.8/dist-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U kaleido\n",
    "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.7.1+cu110.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbSdUju6t7Mw",
    "outputId": "7ffaeb1b-127f-491f-cb67-be3da00f90f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ocp\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Obtaining file:///content/ocp\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Installing collected packages: ocp-models\n",
      "  Running setup.py develop for ocp-models\n",
      "Successfully installed ocp-models\n"
     ]
    }
   ],
   "source": [
    "%cd ocp\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YEWU4N4BuQR",
    "outputId": "fa9a83b0-a33e-4f3e-d83f-e1b97eda6e35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Patron\\\\Downloads',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\python39.zip',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\Patron\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\Patron\\\\.ipython',\n",
       " '/usr/local/lib/python3.8/dist-packages',\n",
       " '/users/patron/anaconda3/lib/site-packages']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.8/dist-packages')\n",
    "sys.path.append('/users/patron/anaconda3/lib/site-packages')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "54-8PbCfCnVx",
    "outputId": "8e0e9e70-323d-482e-f6eb-23abd940ffc7"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-44ee11a8d64d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: chdir() missing required argument 'path' (pos 1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A7gSeDHGcuAo"
   },
   "outputs": [],
   "source": [
    "import ase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mV19EgU5BaVb"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29096\\1675573320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "import logging\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "#from ase import Atoms, Atom\n",
    "#import pygraphviz\n",
    "\n",
    "#import lmdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Batch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from ase.visualize.plot import plot_atoms\n",
    "from ase.visualize import view\n",
    "from ocpmodels.preprocessing import AtomsToGraphs\n",
    "#from ocpmodels.datasets import LmdbDataset\n",
    "import ase.io\n",
    "from ase.build import bulk\n",
    "from ase.build import fcc100, add_adsorbate, molecule\n",
    "from ase.constraints import FixAtoms\n",
    "from ase.calculators.emt import EMT\n",
    "from ase.optimize import BFGS\n",
    "from ocpmodels.common import distutils\n",
    "#from ocpmodels.common.registry import registry\n",
    "from ocpmodels.common.utils import pyg2_data_transform\n",
    "from ocpmodels.datasets import SinglePointLmdbDataset, TrajectoryLmdbDataset\n",
    "'''\n",
    "class LmdbDataset(Dataset):\n",
    "    r\"\"\"Dataset class to load from LMDB files containing relaxation\n",
    "    trajectories or single point computations.\n",
    "    Useful for Structure to Energy & Force (S2EF), Initial State to\n",
    "    Relaxed State (IS2RS), and Initial State to Relaxed Energy (IS2RE) tasks.\n",
    "    Args:\n",
    "            config (dict): Dataset configuration\n",
    "            transform (callable, optional): Data transform function.\n",
    "                    (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(LmdbDataset, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.path = Path(self.config[\"src\"])\n",
    "        if not self.path.is_file():\n",
    "            db_paths = sorted(self.path.glob(\"*.lmdb\"))\n",
    "            assert len(db_paths) > 0, f\"No LMDBs found in '{self.path}'\"\n",
    "\n",
    "            self.metadata_path = self.path / \"metadata.npz\"\n",
    "\n",
    "            self._keys, self.envs = [], []\n",
    "            for db_path in db_paths:\n",
    "                self.envs.append(self.connect_db(db_path))\n",
    "                length = pickle.loads(\n",
    "                    self.envs[-1].begin().get(\"length\".encode(\"ascii\"))\n",
    "                )\n",
    "                self._keys.append(list(range(length)))\n",
    "\n",
    "            keylens = [len(k) for k in self._keys]\n",
    "            self._keylen_cumulative = np.cumsum(keylens).tolist()\n",
    "            self.num_samples = sum(keylens)\n",
    "        else:\n",
    "            self.metadata_path = self.path.parent / \"metadata.npz\"\n",
    "            self.env = self.connect_db(self.path)\n",
    "            self._keys = [\n",
    "                f\"{j}\".encode(\"ascii\")\n",
    "                for j in range(self.env.stat()[\"entries\"])\n",
    "            ]\n",
    "            self.num_samples = len(self._keys)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.path.is_file():\n",
    "            # Figure out which db this should be indexed from.\n",
    "            db_idx = bisect.bisect(self._keylen_cumulative, idx)\n",
    "            # Extract index of element within that db.\n",
    "            el_idx = idx\n",
    "            if db_idx != 0:\n",
    "                el_idx = idx - self._keylen_cumulative[db_idx - 1]\n",
    "            assert el_idx >= 0\n",
    "\n",
    "            # Return features.\n",
    "            datapoint_pickled = (\n",
    "                self.envs[db_idx]\n",
    "                .begin()\n",
    "                .get(f\"{self._keys[db_idx][el_idx]}\".encode(\"ascii\"))\n",
    "            )\n",
    "            data_object = pyg2_data_transform(pickle.loads(datapoint_pickled))\n",
    "            data_object.id = f\"{db_idx}_{el_idx}\"\n",
    "        else:\n",
    "            datapoint_pickled = self.env.begin().get(self._keys[idx])\n",
    "            data_object = pyg2_data_transform(pickle.loads(datapoint_pickled))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            data_object = self.transform(data_object)\n",
    "\n",
    "        return data_object\n",
    "\n",
    "    def connect_db(self, lmdb_path=None):\n",
    "        env = lmdb.open(\n",
    "            str(lmdb_path),\n",
    "            subdir=False,\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=False,\n",
    "            meminit=False,\n",
    "            max_readers=1,\n",
    "        )\n",
    "        return env\n",
    "\n",
    "    def close_db(self):\n",
    "        if not self.path.is_file():\n",
    "            for env in self.envs:\n",
    "                env.close()\n",
    "        else:\n",
    "            self.env.close()\n",
    "\n",
    "\n",
    "class SinglePointLmdbDataset(LmdbDataset):\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(SinglePointLmdbDataset, self).__init__(config, transform)\n",
    "        warnings.warn(\n",
    "            \"SinglePointLmdbDataset is deprecated and will be removed in the future.\"\n",
    "            \"Please use 'LmdbDataset' instead.\",\n",
    "            stacklevel=3,\n",
    "        )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Tj_ZDvx2AZS"
   },
   "outputs": [],
   "source": [
    "train_src = \"/content/drive/MyDrive/MBG Research/OpenCatalyst/data.lmdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99DS_Js4sJj0"
   },
   "outputs": [],
   "source": [
    "train_dataset = SinglePointLmdbDataset({\"src\": train_src})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40fyR4CtecSQ"
   },
   "outputs": [],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYio9mFo3ZSW"
   },
   "outputs": [],
   "source": [
    "data0 = train_dataset[0]\n",
    "data1 = train_dataset[1]\n",
    "data2 = train_dataset[2]\n",
    "data3 = train_dataset[3]\n",
    "data4 = train_dataset[4]\n",
    "data5 = train_dataset[5]\n",
    "data6 = train_dataset[6]\n",
    "data7 = train_dataset[7]\n",
    "data8 = train_dataset[8]\n",
    "data9 = train_dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVVGUvJMuOD6"
   },
   "outputs": [],
   "source": [
    "data0.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_O0fCwKCYTr"
   },
   "outputs": [],
   "source": [
    "def datatographimage(data):\n",
    "  atomic_num = data.atomic_numbers  \n",
    "  atomic_num = atomic_num.tolist()\n",
    "  atomic_num = [int(x) for x in atomic_num]\n",
    "  np.unique(atomic_num)\n",
    "  elem_sym = []\n",
    "  from PyAstronomy import pyasl\n",
    "  an = pyasl.AtomicNo()\n",
    "  for i in atomic_num:\n",
    "    elem_sym.append(an.getElSymbol(i))\n",
    "  G = torch_geometric.utils.to_networkx(data, to_undirected=True)\n",
    "  edge_x = []\n",
    "  edge_y = []\n",
    "  for edge in G.edges():\n",
    "      x0, y0 = nx.circular_layout(G)[edge[0]]\n",
    "      x1, y1 = nx.circular_layout(G)[edge[1]]\n",
    "      edge_x.append(x0)\n",
    "      edge_x.append(x1)\n",
    "      edge_x.append(None)\n",
    "      edge_y.append(y0)\n",
    "      edge_y.append(y1)\n",
    "      edge_y.append(None)\n",
    "\n",
    "  edge_trace = go.Scatter(\n",
    "      x=edge_x, y=edge_y,\n",
    "      line=dict(width=0.5, color='#888'),\n",
    "      hoverinfo='none',\n",
    "      mode='lines')\n",
    "  node_x = []\n",
    "  node_y = []\n",
    "  for node in G.nodes():\n",
    "      x, y = nx.circular_layout(G)[node]\n",
    "      node_x.append(x)\n",
    "      node_y.append(y)\n",
    "\n",
    "  node_df = pd.DataFrame({\"x_pos\":node_x, \"y_pos\":node_y, \"element\":elem_sym})\n",
    "\n",
    "  node_trace  = px.scatter(node_df, x='x_pos', y='y_pos', color='element')\n",
    "  fig = node_trace.add_trace(edge_trace)\n",
    "  fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    "  )\n",
    "  fig.update_layout(\n",
    "      autosize=False,\n",
    "      width=1000,\n",
    "      height=1000)\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PnzWqjVDLlv"
   },
   "outputs": [],
   "source": [
    "datatographimage(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U60vzVDawICS"
   },
   "outputs": [],
   "source": [
    "datatographimage(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0xstSwUvG-z"
   },
   "outputs": [],
   "source": [
    "datatographimage(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlkmpqLXw0dm"
   },
   "outputs": [],
   "source": [
    "datatographimage(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgDJzLI0WE17"
   },
   "outputs": [],
   "source": [
    "datatographimage(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obanYQMv0PD8"
   },
   "outputs": [],
   "source": [
    "datatographimage(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kA29-Xt0rSY"
   },
   "outputs": [],
   "source": [
    "datatographimage(data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNTWOIF4HNhm"
   },
   "outputs": [],
   "source": [
    "datatographimage(data7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUvU9abcGPXa"
   },
   "outputs": [],
   "source": [
    "datatographimage(data8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvNHpVoRTpPe"
   },
   "outputs": [],
   "source": [
    "def viz3d(data):\n",
    "  atomic_num = data.atomic_numbers  \n",
    "  atomic_num = atomic_num.tolist()\n",
    "  atomic_num = [int(x) for x in atomic_num]\n",
    "  np.unique(atomic_num)\n",
    "  elem_sym = []\n",
    "  from PyAstronomy import pyasl\n",
    "  an = pyasl.AtomicNo()\n",
    "  for i in atomic_num:\n",
    "    elem_sym.append(an.getElSymbol(i))\n",
    "  \n",
    "  atoms = []\n",
    "\n",
    "  for i in range(len(data.pos)):\n",
    "    pos = tuple(data.pos.tolist()[i])\n",
    "    element = elem_sym[i]\n",
    "    atoms.append(Atom(element, pos))\n",
    "  atoms = Atoms(atoms)\n",
    "  return view(atoms, viewer='x3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLdVdtZ4WA5M"
   },
   "outputs": [],
   "source": [
    "viz3d(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEbIL1clWPyt"
   },
   "outputs": [],
   "source": [
    "viz3d(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tlSVdnfRKPF"
   },
   "outputs": [],
   "source": [
    "viz3d(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WnJQPcOTg3K"
   },
   "outputs": [],
   "source": [
    "viz3d(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7ltSJ6oaLEY"
   },
   "outputs": [],
   "source": [
    "viz3d(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YhaPQkNhmA3"
   },
   "outputs": [],
   "source": [
    "viz3d(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sbdluCgVnKx"
   },
   "outputs": [],
   "source": [
    "viz3d(data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbeGFKYShqCZ"
   },
   "outputs": [],
   "source": [
    "viz3d(data7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deFeEHIpYEn7"
   },
   "outputs": [],
   "source": [
    "viz3d(data8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBLbRJ3ehs33"
   },
   "outputs": [],
   "source": [
    "viz3d(data9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wx4T-a8fh_AH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
